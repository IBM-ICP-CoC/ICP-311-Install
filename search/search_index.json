{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Installing IBM Cloud Private in IBM Cloud Virtual Machines This document will walk you through the steps needed to create virtual machines in IBM Cloud and use them to run IBM Cloud Private. It should be noted that the instructions on this site were captured while configuring and installing on RHEL virtual servers hosted on IBM Cloud (Softlayer). Some of the server setup steps may vary if you are attempting to provision virtual servers in another cloud provider or if you are installing on a different OS. In this example, we will be installing Docker EE and ICP 3.1.1 Enterprise edtion on RHEL. The docker EE edition is install file is included with the download of ICP 3.1.1. These are the files you will need. ibm-cloud-private-x86_64-3.1.1.tar.gz icp-docker-18.03.1_x86_64.bin Note If you are an IBM'er, you can download the install files from the Software Sellerrs Workplace . You will need to log in and do a search for IBM Cloud Private 3.1.1 . The package assembly you need to look for is: IBM Cloud Private Installation Packages eAssembly (CJ4MTEN) IBM Cloud Private 3.1.1 for Linux (x86_64) Docker (CNXC8EN) IBM Cloud Private 3.1.1 Docker for Linux (x86_64) (CNXD2EN) Acknowledgments Dave Wakeman (Public) Dave Krier (Dist) are the authors of this install guide. Dave Weilert (COC Team) was the pioneer who documented the install process and perfected all the pre-req steps. Jim Conallen (COC Team) authored the LDAP setup and configuration guide. Tom Watson (Dist) testing and adding comments. Danger This is NOT a replacement for the official documentation for IBM Cloud Private! It is intended only to be a learning guide, and uses an arbitrary configuration that may not be appropriate for production use.","title":"Home"},{"location":"#installing-ibm-cloud-private-in-ibm-cloud-virtual-machines","text":"This document will walk you through the steps needed to create virtual machines in IBM Cloud and use them to run IBM Cloud Private. It should be noted that the instructions on this site were captured while configuring and installing on RHEL virtual servers hosted on IBM Cloud (Softlayer). Some of the server setup steps may vary if you are attempting to provision virtual servers in another cloud provider or if you are installing on a different OS. In this example, we will be installing Docker EE and ICP 3.1.1 Enterprise edtion on RHEL. The docker EE edition is install file is included with the download of ICP 3.1.1. These are the files you will need. ibm-cloud-private-x86_64-3.1.1.tar.gz icp-docker-18.03.1_x86_64.bin Note If you are an IBM'er, you can download the install files from the Software Sellerrs Workplace . You will need to log in and do a search for IBM Cloud Private 3.1.1 . The package assembly you need to look for is: IBM Cloud Private Installation Packages eAssembly (CJ4MTEN) IBM Cloud Private 3.1.1 for Linux (x86_64) Docker (CNXC8EN) IBM Cloud Private 3.1.1 Docker for Linux (x86_64) (CNXD2EN)","title":"Installing IBM Cloud Private in IBM Cloud Virtual Machines"},{"location":"#acknowledgments","text":"Dave Wakeman (Public) Dave Krier (Dist) are the authors of this install guide. Dave Weilert (COC Team) was the pioneer who documented the install process and perfected all the pre-req steps. Jim Conallen (COC Team) authored the LDAP setup and configuration guide. Tom Watson (Dist) testing and adding comments. Danger This is NOT a replacement for the official documentation for IBM Cloud Private! It is intended only to be a learning guide, and uses an arbitrary configuration that may not be appropriate for production use.","title":"Acknowledgments"},{"location":"createvms/","text":"Create the Virtual Machines Provision 5 virtual machines with this configuration: RHEL Minimal (7.x) 8 CPU / 16G Mem 100GB Boot Disk 200GB Disk 1 500GB Disk 2 Tip You can create all 5 VMs at the same time with the same configuration by using the Quantity field on the order page. To create virtual machines: Login to your IBM Cloud account. Click the Create Resource button on the Dashboard page Click the Virtual Server tile. Specify the following settings for your Virtual Server Instance: The Public Virtual Server tile should be selected; click Continue . Choose Public as the type of virtual server Set the Quantity to 5 Specify values for Host Name and Domain Choose the location and data center of your choice Choose the Balanced B1.8x16 profile. You many need to choose the All Profiles tab to find it. Choose Red Hat as the Image (take the default 7.x Minimal (64-bit) - HVM ). Make sure you actually cick the Red Hat box and that it has a blue outline and the blue checkmark. In the Attached Storage Disks section, click the Add New button twice to create two new disks, named Disk 1 and Disk 2 change the size of the disks: Boot Disk to 100 GB Disk 1 to 200 GB Disk 2 to 500 GB When finished the screen should look like this: Click the checkbox to acknowledge that you have read and agree to the third party agreements and click Create . Note These values for host name and domain do not have any affect on the actual host name and domain defined inside the virtual machines. They are just labels and can be changed at any time. Note When you chose a quantity greater than 1 your virtual machines may have an added sequence number in their host names. Don't forget that you can change the names of your virtual machines after they are created. The name of your VM's in the IBM Cloud Infrastructure section are just for your own reference. It's best practice to name each of them with some indication on what role they will play in your cluster, such as (master, mgmt, worker, va, proxy) Tip You will need to transfer a very large file to your master node. Once your machines are created, you can initiate this transfer. You will need to know the password for root , which you can get from the Passwords tab on the Device Details page. To transfer the file open a terminal window on your host machine, navigate to the directory where the file is stored and execute this command: scp ibm-cloud-private-x86_64-3.1.1.tar.gz root@ your Master node IP :/tmp The scp command is the Secure File Transfer command. When your machines are provisioned it will be helpful for you to collect some information together that you will need later. The table below is an example of what you should collect. The hostnames can be whatever values you want. The passwords are for the root user and can be obtained on the Passwords tab of the Details page for your device. Machine Role hostname IP Address Password Master/Proxy/Boot my-icp-master xxx.xxx.xxx.xxx xxxxxxxx Management my-icp-mgmt xxx.xxx.xxx.xxx xxxxxxxx VA my-icp-va xxx.xxx.xxx.xxx xxxxxxxx Worker1 my-icp-worker1 xxx.xxx.xxx.xxx xxxxxxxx Worker2 my-icp-worker2 xxx.xxx.xxx.xxx xxxxxxxx Note I recommend you use the Public IPs for all your virtual machines. You can use the Private IP for everything except the PROXY node if you really want to, but you must be consistent in all the next steps for everything to work properly.","title":"Creating VMs"},{"location":"createvms/#create-the-virtual-machines","text":"Provision 5 virtual machines with this configuration: RHEL Minimal (7.x) 8 CPU / 16G Mem 100GB Boot Disk 200GB Disk 1 500GB Disk 2 Tip You can create all 5 VMs at the same time with the same configuration by using the Quantity field on the order page. To create virtual machines: Login to your IBM Cloud account. Click the Create Resource button on the Dashboard page Click the Virtual Server tile. Specify the following settings for your Virtual Server Instance: The Public Virtual Server tile should be selected; click Continue . Choose Public as the type of virtual server Set the Quantity to 5 Specify values for Host Name and Domain Choose the location and data center of your choice Choose the Balanced B1.8x16 profile. You many need to choose the All Profiles tab to find it. Choose Red Hat as the Image (take the default 7.x Minimal (64-bit) - HVM ). Make sure you actually cick the Red Hat box and that it has a blue outline and the blue checkmark. In the Attached Storage Disks section, click the Add New button twice to create two new disks, named Disk 1 and Disk 2 change the size of the disks: Boot Disk to 100 GB Disk 1 to 200 GB Disk 2 to 500 GB When finished the screen should look like this: Click the checkbox to acknowledge that you have read and agree to the third party agreements and click Create . Note These values for host name and domain do not have any affect on the actual host name and domain defined inside the virtual machines. They are just labels and can be changed at any time. Note When you chose a quantity greater than 1 your virtual machines may have an added sequence number in their host names. Don't forget that you can change the names of your virtual machines after they are created. The name of your VM's in the IBM Cloud Infrastructure section are just for your own reference. It's best practice to name each of them with some indication on what role they will play in your cluster, such as (master, mgmt, worker, va, proxy) Tip You will need to transfer a very large file to your master node. Once your machines are created, you can initiate this transfer. You will need to know the password for root , which you can get from the Passwords tab on the Device Details page. To transfer the file open a terminal window on your host machine, navigate to the directory where the file is stored and execute this command: scp ibm-cloud-private-x86_64-3.1.1.tar.gz root@ your Master node IP :/tmp The scp command is the Secure File Transfer command. When your machines are provisioned it will be helpful for you to collect some information together that you will need later. The table below is an example of what you should collect. The hostnames can be whatever values you want. The passwords are for the root user and can be obtained on the Passwords tab of the Details page for your device. Machine Role hostname IP Address Password Master/Proxy/Boot my-icp-master xxx.xxx.xxx.xxx xxxxxxxx Management my-icp-mgmt xxx.xxx.xxx.xxx xxxxxxxx VA my-icp-va xxx.xxx.xxx.xxx xxxxxxxx Worker1 my-icp-worker1 xxx.xxx.xxx.xxx xxxxxxxx Worker2 my-icp-worker2 xxx.xxx.xxx.xxx xxxxxxxx Note I recommend you use the Public IPs for all your virtual machines. You can use the Private IP for everything except the PROXY node if you really want to, but you must be consistent in all the next steps for everything to work properly.","title":"Create the Virtual Machines"},{"location":"customurl/","text":"Customizing the cluster access URL You can get your own domain name from IBM Cloud. Once it gets created you can add an A record for your ICP environment. Attention Capture the steps to do this including screen shots To use a custom URL for your cluster follow the instructions here","title":"Using a custom URL"},{"location":"customurl/#customizing-the-cluster-access-url","text":"You can get your own domain name from IBM Cloud. Once it gets created you can add an A record for your ICP environment. Attention Capture the steps to do this including screen shots To use a custom URL for your cluster follow the instructions here","title":"Customizing the cluster access URL"},{"location":"installicp/","text":"Install IBM Cloud Private Note The rest of the installation will take place only on the Master node. At this time you should ssh into your master node as root . Unpack the installer Inside of the virtual machine for your master node, create a new directory called /opt/icp311 in a terminal window on your laptop, execute this command: scp ibm-cloud-private-x86_64-3.1.1.tar.gz root@ your-master-node-ip :/opt/icp311 Note If you have already transferred it the file will be in /tmp so you can use this command instead: mv /tmp/ibm-cloud-private-x86_64-3.1.1.tar.gz /opt/icp311 Expand the tarball (from /opt/icp311 directory) /usr/bin/tar xf ibm-cloud-private-x86_64-3.1.1.tar.gz -O | docker load Note This command may take several minutes to run Create inception (run the docker image from the /opt/icp311 directory) docker run -v $(pwd):/data -e LICENSE=accept ibmcom/icp-inception-amd64:3.1.1-ee cp -r cluster /data Move the image files for your cluster to the / installation_directory /cluster/images folder. Create a new folder under the /cluster directory called images . mv ibm-cloud-private-x86_64-3.1.1.tar.gz cluster/images/ Copy the SSH Key to the keys (run this command from the /opt/icp311 directory) cp ~/.ssh/id_rsa ./cluster/ssh_key Edit the hosts file (found in the /opt/icp311/cluster directory) [master] your-master-ip [worker] your-worker1-ip your-worker2-ip [proxy] your-master-ip [management] your-management-ip [va] your-va-ip Warning The default hosts file has the management and va sections commented out. Be sure to remove the # comment markers or your install will fail!! Also, remove the line with the three dots ... in the [worker] section. Edit cluster/config.yaml file for custom settings ## Advanced Settings default_admin_user: admin default_admin_password: set your admin password here management_services: vulnerability-advisor: enabled As root run the installer (from the /opt/icp311/cluster directory) docker run --net=host -t -e LICENSE=accept -v $(pwd) :/installer/cluster ibmcom/icp-inception-amd64:3.1.1-ee install Success If all goes well your install will finish successfully and you will be good to go. Failure If the install fails you need to run the uninstall command before you run the installer again. docker run --net=host -t -e LICENSE=accept -v $(pwd) :/installer/cluster ibmcom/icp-inception-amd64:3.1.1-ee uninstall Happy hosting!","title":"Installation"},{"location":"installicp/#install-ibm-cloud-private","text":"Note The rest of the installation will take place only on the Master node. At this time you should ssh into your master node as root .","title":"Install IBM Cloud Private"},{"location":"installicp/#unpack-the-installer","text":"Inside of the virtual machine for your master node, create a new directory called /opt/icp311 in a terminal window on your laptop, execute this command: scp ibm-cloud-private-x86_64-3.1.1.tar.gz root@ your-master-node-ip :/opt/icp311 Note If you have already transferred it the file will be in /tmp so you can use this command instead: mv /tmp/ibm-cloud-private-x86_64-3.1.1.tar.gz /opt/icp311 Expand the tarball (from /opt/icp311 directory) /usr/bin/tar xf ibm-cloud-private-x86_64-3.1.1.tar.gz -O | docker load Note This command may take several minutes to run Create inception (run the docker image from the /opt/icp311 directory) docker run -v $(pwd):/data -e LICENSE=accept ibmcom/icp-inception-amd64:3.1.1-ee cp -r cluster /data Move the image files for your cluster to the / installation_directory /cluster/images folder. Create a new folder under the /cluster directory called images . mv ibm-cloud-private-x86_64-3.1.1.tar.gz cluster/images/ Copy the SSH Key to the keys (run this command from the /opt/icp311 directory) cp ~/.ssh/id_rsa ./cluster/ssh_key Edit the hosts file (found in the /opt/icp311/cluster directory) [master] your-master-ip [worker] your-worker1-ip your-worker2-ip [proxy] your-master-ip [management] your-management-ip [va] your-va-ip Warning The default hosts file has the management and va sections commented out. Be sure to remove the # comment markers or your install will fail!! Also, remove the line with the three dots ... in the [worker] section. Edit cluster/config.yaml file for custom settings ## Advanced Settings default_admin_user: admin default_admin_password: set your admin password here management_services: vulnerability-advisor: enabled As root run the installer (from the /opt/icp311/cluster directory) docker run --net=host -t -e LICENSE=accept -v $(pwd) :/installer/cluster ibmcom/icp-inception-amd64:3.1.1-ee install Success If all goes well your install will finish successfully and you will be good to go. Failure If the install fails you need to run the uninstall command before you run the installer again. docker run --net=host -t -e LICENSE=accept -v $(pwd) :/installer/cluster ibmcom/icp-inception-amd64:3.1.1-ee uninstall Happy hosting!","title":"Unpack the installer"},{"location":"ldap/","text":"Installing and Configuring LDAP You can run the LDAP server on any one of the nodes, but I would suggest you run it either on the master or boot node. I choose to run this on a separate stand alone server. All it requires is that docker is installed. Warning If you plan in Customizing the cluster access URL you should configure that BEFORE you configure any LDAP connections. Create two new directories: mkdir -p /opt/openldap/slapd.d mkdir -p /opt/openldap/ldap docker run -d -e DOMAIN=mycluster.icp --net=host --name=openldap \\--restart unless-stopped \\ -v /opt/openldap/ldap:/var/lib/ldap \\ -v /opt/openldap/slapd.d:/etc/ldap/slapd.d \\ siji/openldap:2.4.42 Note The command above will run a docker image containing LDAP and set it to automatically restart if the virtual machine is restarted. THANK YOU to Jim Conallen, for the following documentation!! Directions for configuring LDAP can be found here .","title":"Installing and Configuring LDAP"},{"location":"ldap/#installing-and-configuring-ldap","text":"You can run the LDAP server on any one of the nodes, but I would suggest you run it either on the master or boot node. I choose to run this on a separate stand alone server. All it requires is that docker is installed. Warning If you plan in Customizing the cluster access URL you should configure that BEFORE you configure any LDAP connections. Create two new directories: mkdir -p /opt/openldap/slapd.d mkdir -p /opt/openldap/ldap docker run -d -e DOMAIN=mycluster.icp --net=host --name=openldap \\--restart unless-stopped \\ -v /opt/openldap/ldap:/var/lib/ldap \\ -v /opt/openldap/slapd.d:/etc/ldap/slapd.d \\ siji/openldap:2.4.42 Note The command above will run a docker image containing LDAP and set it to automatically restart if the virtual machine is restarted. THANK YOU to Jim Conallen, for the following documentation!! Directions for configuring LDAP can be found here .","title":"Installing and Configuring LDAP"},{"location":"master/","text":"Setup on Boot/Master/Proxy Only","title":"Setup on Boot/Master/Proxy Only"},{"location":"master/#setup-on-bootmasterproxy-only","text":"","title":"Setup on Boot/Master/Proxy Only"},{"location":"setupall/","text":"Setup on All Machines To install IBM Cloud Private you first need to prepare all of your virtual machines. These instructions are specific to the install being done, and were derived from the Preparing your cluster for installation section of the ICP Knowledge Center. They are not reflective of all the steps necessary in all situations. Important There are two scripts that will help you prapare your virtual machines for installation of ICP. modify_fs_v2.sh will prepare the disks and move the /var and /opt directories to the two additional disks provisioned when the VMs were created. install_prereqs.sh takes care of installing MOST of what you will need for the prerequisites. I would encourage you to look at the contents of these scripts to understand what they do. It should also be noted that they are specific to RHEL, so if your using another OS, such as Ubuntu you will have to perform these steps manually using the proper os commands. Install Prerequisites Note The first time you make a secure connection to a remote machine you may see this message: The authenticity of host '169.60.185.59 (169.60.185.59)' can't be established. ECDSA key fingerprint is SHA256:XAs372uCWTkOqLOkXwQYuCXq21GaJFoYIuItUf0xGpc. Are you sure you want to continue connecting (yes/no)? Type in yes and the key fingerprint will be added to your ~/.ssh/known_hosts file. Download install_prereqs.sh and use scp to transfer it to the virtual machine. Inside of the virtual machine use this command to change the permissions: chmod 777 install_prereqs.sh Execute the script: ./install_prereqs.sh Modify the disks When the virtual machine was created two additional disks were added to the configuration, but they are not yet configured inside the virtual machine. These two disks are to be used for the /opt and /var directories. Download modify_fs_v2.sh and use scp to transfer it to the virtual machine. Inside of the virtual machine use this command to change permissions: chmod 777 modify_fs_v2.sh Execute the script: ./modify_fs_v2.sh 199 499 --- The parameters correspond to the sizes of Disk 1 and Disk 2 (minus 1) Install Docker SCP copy the docker file (This is the IBM Docker Enterprise version) to your local machine (icp-docker-18.03.1_x86_64.bin is available with the download of ICP 3.1.1 EE) From your local machine you need to SCP transfer the file to each ICP server Make an install dir on server (In this example I created the install dir on the root dir) mkdir install chmod dir 777 install Open Terminal window on local machine Navigate to dir where file is located scp command: scp ./icp-docker-18.03.1_x86_64.bin login@icp-server-ip:/install/ On the server you should now see the docker file. docker install commands chmod 777 on the file``` ./icp-docker-18.03.1_x86_64.bin --install``` systemctl start docker systemctl enable docker Disable the firewall systemctl disable firewalld systemctl stop firewalld Rename the virtual machine hostnamectl set-hostname new name Update the hosts file Make sure that the /etc/hosts file on each virtual machine has entries for all of the other virtual machines so that they can talk to each other. Take note of what your host names are, you will need them in the following steps. Setup SSH keys Generate the KEY on each node cd /root ;ssh-keygen -b 4096 -f /root/.ssh/id_rsa -N ;cat ~/.ssh/id_rsa.pub | sudo tee -a ~/.ssh/authorized_keys Copy the key to each of the other nodes DO NOT just copy these commands below, they are for example ONLY. You need to edit the host names at the end of each of these commands. You will need to run ALL of these commands to copy the SSH key from the current VM to all the rest of the VM's in the cluster. We are sharing the SSH keys, so that the install script can SSH into the other boxes without authentication. ssh-copy-id -i .ssh/id_rsa.pub root@dak311master ssh-copy-id -i .ssh/id_rsa.pub root@dak311mgmt ssh-copy-id -i .ssh/id_rsa.pub root@dak311va ssh-copy-id -i .ssh/id_rsa.pub root@dak311worker1 ssh-copy-id -i .ssh/id_rsa.pub root@dak311worker2 Test the SSH keys You can perform a simple test to ensure that the SSH keys are setup correctly. At this point you should be able to SSH into any one of the VM's from any one of the VM's. Try it out and spot check the SSH keys. As an example: I am logged into the master node. I should be able to type this command below and log directly into the worker1 node without any authentication propts. The example below assumes the host name for worker1 is dak311worker1, yours may be different. ssh dak311worker1 Success You should now see that your logged into the worker 1 node and you didn't see any prompts for userid or password.","title":"Setup on All VMs"},{"location":"setupall/#setup-on-all-machines","text":"To install IBM Cloud Private you first need to prepare all of your virtual machines. These instructions are specific to the install being done, and were derived from the Preparing your cluster for installation section of the ICP Knowledge Center. They are not reflective of all the steps necessary in all situations. Important There are two scripts that will help you prapare your virtual machines for installation of ICP. modify_fs_v2.sh will prepare the disks and move the /var and /opt directories to the two additional disks provisioned when the VMs were created. install_prereqs.sh takes care of installing MOST of what you will need for the prerequisites. I would encourage you to look at the contents of these scripts to understand what they do. It should also be noted that they are specific to RHEL, so if your using another OS, such as Ubuntu you will have to perform these steps manually using the proper os commands.","title":"Setup on All Machines"},{"location":"setupall/#install-prerequisites","text":"Note The first time you make a secure connection to a remote machine you may see this message: The authenticity of host '169.60.185.59 (169.60.185.59)' can't be established. ECDSA key fingerprint is SHA256:XAs372uCWTkOqLOkXwQYuCXq21GaJFoYIuItUf0xGpc. Are you sure you want to continue connecting (yes/no)? Type in yes and the key fingerprint will be added to your ~/.ssh/known_hosts file. Download install_prereqs.sh and use scp to transfer it to the virtual machine. Inside of the virtual machine use this command to change the permissions: chmod 777 install_prereqs.sh Execute the script: ./install_prereqs.sh","title":"Install Prerequisites"},{"location":"setupall/#modify-the-disks","text":"When the virtual machine was created two additional disks were added to the configuration, but they are not yet configured inside the virtual machine. These two disks are to be used for the /opt and /var directories. Download modify_fs_v2.sh and use scp to transfer it to the virtual machine. Inside of the virtual machine use this command to change permissions: chmod 777 modify_fs_v2.sh Execute the script: ./modify_fs_v2.sh 199 499 --- The parameters correspond to the sizes of Disk 1 and Disk 2 (minus 1)","title":"Modify the disks"},{"location":"setupall/#install-docker","text":"SCP copy the docker file (This is the IBM Docker Enterprise version) to your local machine (icp-docker-18.03.1_x86_64.bin is available with the download of ICP 3.1.1 EE) From your local machine you need to SCP transfer the file to each ICP server Make an install dir on server (In this example I created the install dir on the root dir) mkdir install chmod dir 777 install Open Terminal window on local machine Navigate to dir where file is located scp command: scp ./icp-docker-18.03.1_x86_64.bin login@icp-server-ip:/install/ On the server you should now see the docker file. docker install commands chmod 777 on the file``` ./icp-docker-18.03.1_x86_64.bin --install``` systemctl start docker systemctl enable docker","title":"Install Docker"},{"location":"setupall/#disable-the-firewall","text":"systemctl disable firewalld systemctl stop firewalld","title":"Disable the firewall"},{"location":"setupall/#rename-the-virtual-machine","text":"hostnamectl set-hostname new name","title":"Rename the virtual machine"},{"location":"setupall/#update-the-hosts-file","text":"Make sure that the /etc/hosts file on each virtual machine has entries for all of the other virtual machines so that they can talk to each other. Take note of what your host names are, you will need them in the following steps.","title":"Update the hosts file"},{"location":"setupall/#setup-ssh-keys","text":"","title":"Setup SSH keys"},{"location":"setupall/#generate-the-key-on-each-node","text":"cd /root ;ssh-keygen -b 4096 -f /root/.ssh/id_rsa -N ;cat ~/.ssh/id_rsa.pub | sudo tee -a ~/.ssh/authorized_keys","title":"Generate the KEY on each node"},{"location":"setupall/#copy-the-key-to-each-of-the-other-nodes","text":"DO NOT just copy these commands below, they are for example ONLY. You need to edit the host names at the end of each of these commands. You will need to run ALL of these commands to copy the SSH key from the current VM to all the rest of the VM's in the cluster. We are sharing the SSH keys, so that the install script can SSH into the other boxes without authentication. ssh-copy-id -i .ssh/id_rsa.pub root@dak311master ssh-copy-id -i .ssh/id_rsa.pub root@dak311mgmt ssh-copy-id -i .ssh/id_rsa.pub root@dak311va ssh-copy-id -i .ssh/id_rsa.pub root@dak311worker1 ssh-copy-id -i .ssh/id_rsa.pub root@dak311worker2","title":"Copy the key to each of the other nodes"},{"location":"setupall/#test-the-ssh-keys","text":"You can perform a simple test to ensure that the SSH keys are setup correctly. At this point you should be able to SSH into any one of the VM's from any one of the VM's. Try it out and spot check the SSH keys. As an example: I am logged into the master node. I should be able to type this command below and log directly into the worker1 node without any authentication propts. The example below assumes the host name for worker1 is dak311worker1, yours may be different. ssh dak311worker1 Success You should now see that your logged into the worker 1 node and you didn't see any prompts for userid or password.","title":"Test the SSH keys"}]}